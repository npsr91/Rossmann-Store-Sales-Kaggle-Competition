{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Homework 4 - Rossmann Store Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab\n",
    "import csv\n",
    "import datetime\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from pandas.tseries.offsets import *\n",
    "from operator import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_validation import cross_val_predict, cross_val_score\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn import ensemble\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error, r2_score, make_scorer\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Scoring and Accuracy metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmspe(y, yhat):\n",
    "    return np.sqrt(np.mean((yhat/y-1) ** 2))\n",
    "\n",
    "#Fitting log and then converting back to exponential\n",
    "def rmspe_xg(yhat, y):\n",
    "    y = np.expm1(y.get_label())\n",
    "    yhat = np.expm1(yhat)\n",
    "    return \"rmspe\", rmspe(y,yhat)\n",
    "\n",
    "#Make rmse score function for Scikit\n",
    "scoring_fnc = make_scorer(rmspe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading sales and store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the training, test and store data using pandas\n",
    "\n",
    "nrows = None\n",
    "types = {'CompetitionOpenSinceYear': np.dtype(int),\n",
    "         'CompetitionOpenSinceMonth': np.dtype(int),\n",
    "         'StateHoliday': np.dtype(str),\n",
    "         'Promo2SinceWeek': np.dtype(int),\n",
    "         'SchoolHoliday': np.dtype(float),\n",
    "         'PromoInterval': np.dtype(str)}\n",
    "\n",
    "train = pd.read_csv('train.csv', nrows=nrows,parse_dates=['Date'],date_parser=(lambda dt: pd.to_datetime(dt, format='%Y-%m-%d')), \n",
    "                   dtype = types)\n",
    "nrows = nrows\n",
    "test = pd.read_csv('test.csv', nrows=nrows, parse_dates=['Date'],date_parser=(lambda dt: pd.to_datetime(dt, format='%Y-%m-%d')),\n",
    "                  dtype = types)\n",
    "store = pd.read_csv(\"store.csv\")\n",
    "\n",
    "#Assume store open, if not provided\n",
    "train.fillna(1, inplace=True)\n",
    "test.fillna(1, inplace=True)\n",
    "\n",
    "#Consider only open stores for training\n",
    "train = train[train[\"Open\"] != 0]\n",
    "\n",
    "#Filter sales bigger then zero else rmspe infinite\n",
    "train = train[train[\"Sales\"] > 0]\n",
    "\n",
    "#Join with store\n",
    "train = pd.merge(train, store, on='Store')\n",
    "test = pd.merge(test, store, on='Store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(features, data):\n",
    "    \n",
    "    data.fillna(0, inplace=True)\n",
    "    data.loc[data.Open.isnull(), 'Open'] = 1\n",
    "   \n",
    "    #Selecting variables specific to Store\n",
    "    features.extend(['Store', 'CompetitionDistance', 'CompetitionOpenSinceMonth',\n",
    "                     'CompetitionOpenSinceYear', 'Promo', 'Promo2', 'Promo2SinceWeek', 'Promo2SinceYear'])\n",
    "\n",
    "    #Add SchoolDay\n",
    "    features.append('SchoolHoliday')\n",
    "    data['SchoolHoliday'] = data['SchoolHoliday'].astype(float)\n",
    "    \n",
    "    # Label encode categorical variables\n",
    "    features.extend(['StoreType', 'Assortment', 'StateHoliday'])\n",
    "    mappings = {'0':0, 'a':1, 'b':2, 'c':3, 'd':4}\n",
    "    data.StoreType.replace(mappings, inplace=True)\n",
    "    data.Assortment.replace(mappings, inplace=True)\n",
    "    data.StateHoliday.replace(mappings, inplace=True)\n",
    "\n",
    "    #Create features specific to type of day\n",
    "    features.extend(['DayOfWeek', 'Month', 'Day', 'Year', 'WeekOfYear'])\n",
    "    data['Year'] = data.Date.dt.year\n",
    "    data['Month'] = data.Date.dt.month\n",
    "    data['Day'] = data.Date.dt.day\n",
    "    data['DayOfWeek'] = data.Date.dt.dayofweek\n",
    "    data['WeekOfYear'] = data.Date.dt.weekofyear\n",
    "    \n",
    "    # Promo open time in months\n",
    "    features.append('PromoOpen')\n",
    "    data['PromoOpen'] = 12 * (data.Year - data.Promo2SinceYear) + (data.WeekOfYear - data.Promo2SinceWeek) / 4.0\n",
    "    data['PromoOpen'] = data.PromoOpen.apply(lambda x: x if x > 0 else 0)\n",
    "    data.loc[data.Promo2SinceYear == 0, 'PromoOpen'] = 0\n",
    "    \n",
    "    # Indicate that sales on that day are in promo interval\n",
    "    features.append('IsPromoMonth')\n",
    "    str_month = {1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr', 5:'May', 6:'Jun', \\\n",
    "             7:'Jul', 8:'Aug', 9:'Sept', 10:'Oct', 11:'Nov', 12:'Dec'}\n",
    "    data['monthStr'] = data.Month.map(str_month)\n",
    "    data.loc[data.PromoInterval == 0, 'PromoInterval'] = ''\n",
    "    \n",
    "    #Create whether Month is promo month\n",
    "    data['IsPromoMonth'] = 0\n",
    "    for interval in data.PromoInterval.unique():\n",
    "        if interval != '':\n",
    "            for month in interval.split(','):\n",
    "                data.loc[(data.monthStr == month) & (data.PromoInterval == interval), 'IsPromoMonth'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create train and test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "create_features(features, train)\n",
    "create_features([], test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Store', 'CompetitionDistance', 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Promo', 'Promo2', 'Promo2SinceWeek', 'Promo2SinceYear', 'SchoolHoliday', 'StoreType', 'Assortment', 'StateHoliday', 'DayOfWeek', 'Month', 'Day', 'Year', 'WeekOfYear', 'PromoOpen', 'IsPromoMonth']\n"
     ]
    }
   ],
   "source": [
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[features]\n",
    "y_train = np.log1p(train.Sales)\n",
    "X_test = test[features]\n",
    "#X_train, X_train_test, y_train, y_train_test = train_test_split(X, targets, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scale = StandardScaler().fit(X_train)\n",
    "X_train_std = std_scale.transform(X_train)\n",
    "X_test_std = std_scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  4.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'fit_intercept': [True, False], 'normalize': [True, False], 'copy_X': [True, False], 'alpha': [0.1, 1.0, 10.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=make_scorer(rmspe), verbose=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lasso regularization \n",
    "param = {'fit_intercept':[True,False], 'normalize':[True,False], 'copy_X':[True, False], 'alpha':[0.1,1.0,10.0]}\n",
    "lasso_reg = linear_model.Lasso()\n",
    "gs = GridSearchCV(lasso_reg, param_grid = param, scoring= scoring_fnc, cv=5, verbose=1)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.049452882111151876\n",
      "0.0020098931954629505\n"
     ]
    }
   ],
   "source": [
    "lasso_regr = gs.best_estimator_\n",
    "lasso_regr.fit(X_train, y_train)\n",
    "scores = cross_val_score(lasso_regr,X_train,y_train,cv=5,scoring=scoring_fnc)\n",
    "print(scores.mean())\n",
    "print(scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs=lasso_regr.predict(X_test_std)\n",
    "# Make Submission\n",
    "result = pd.DataFrame({\"Id\": test[\"Id\"], 'Sales': np.expm1(test_probs)})\n",
    "result.to_csv(\"lasso_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Private Score - 0.46**  \n",
    "**Public Score - 0.429**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04836313542743356\n",
      "0.0020732140565679147\n"
     ]
    }
   ],
   "source": [
    "# Ridge regularization \n",
    "param = {'fit_intercept':[True,False], 'normalize':[True,False], 'copy_X':[True, False], 'alpha':[0.1,1.0,10.0]}\n",
    "ridge_reg = linear_model.Ridge()\n",
    "gs = GridSearchCV(ridge_reg, param_grid = param, scoring= scoring_fnc, cv=5, verbose=1)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "ridge_regr = gs.best_estimator_\n",
    "ridge_regr.fit(X_train, y_train)\n",
    "scores = cross_val_score(ridge_regr,X_train,y_train,cv=5,scoring=scoring_fnc)\n",
    "print(scores.mean())\n",
    "print(scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs=ridge_regr.predict(X_test_std)\n",
    "# Make Submissionccv_s\n",
    "result = pd.DataFrame({\"Id\": test[\"Id\"], 'Sales': np.expm1(test_probs)})\n",
    "result.to_csv(\"ridge_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Private Score - 0.45**  \n",
    "**Public Score - 0.421**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 35 candidates, totalling 175 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 175 out of 175 | elapsed:  6.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04819799017873186\n",
      "0.003061535478218888\n"
     ]
    }
   ],
   "source": [
    "X_train = train[features]\n",
    "y_train = np.log1p(train.Sales)\n",
    "X_test = test[features]\n",
    "#X_train, X_train_test, y_train, y_train_test = train_test_split(X, targets, test_size=0.20, random_state=15)\n",
    "\n",
    "\n",
    "param = {'max_depth': np.arange(3, 10), 'min_samples_split' : range(10,100,20)}\n",
    "dtc = DecisionTreeRegressor()\n",
    "\n",
    "gs = GridSearchCV(dtc, param_grid=param, scoring=scoring_fnc, cv=5, verbose=1)\n",
    "gs.fit(X_train, y_train)\n",
    "dt_model = gs.best_estimator_\n",
    "dt_model.fit(X_train, y_train)\n",
    "scores = cross_val_score(dt_model, X_train,y_train,cv=5,scoring=scoring_fnc)\n",
    "print(scores.mean())\n",
    "print(scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs=dt_model.predict(X_test)\n",
    "# Make Submission\n",
    "result = pd.DataFrame({\"Id\": test[\"Id\"], 'Sales': np.expm1(test_probs)})\n",
    "result.to_csv(\"dt_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Private Score - 0.334**  \n",
    "**Public Score - 0.32**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[features]\n",
    "y_train = np.log1p(train.Sales)\n",
    "X_test = test[features]\n",
    "#X_train, X_train_test, y_train, y_train_test = train_test_split(X, targets, test_size=0.20, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    }
   ],
   "source": [
    "rf = ensemble.RandomForestRegressor(bootstrap = True)\n",
    "param = {'max_depth': [10,20],\n",
    "         'min_samples_split': [10,20],\n",
    "         'n_estimators': [150, 200]}\n",
    "\n",
    "gs = RandomizedSearchCV(rf, param_distributions=param, n_iter=6, scoring=scoring_fnc, cv=5, verbose=1, n_jobs =-1)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   42.2s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  3.0min finished\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   33.6s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  2.2min finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 150 out of 150 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   32.1s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  2.3min finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 150 out of 150 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   33.9s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  2.4min finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 150 out of 150 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   33.5s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  2.3min finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 150 out of 150 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   34.7s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  2.3min finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04958165218512673\n",
      "0.0018085442263876495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 150 out of 150 | elapsed:    0.6s finished\n"
     ]
    }
   ],
   "source": [
    "rf_regr = ensemble.RandomForestRegressor(n_estimators=150, max_depth=20, min_samples_split=10, bootstrap=True, n_jobs=-1, \n",
    "                                         random_state=123, verbose = 1)\n",
    "rf_regr.fit(X_train, y_train)\n",
    "scores = cross_val_score(rf_regr,X_train,y_train,cv=5,scoring=scoring_fnc)\n",
    "print(scores.mean())\n",
    "print(scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 150 out of 150 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "test_probs=rf_regr.predict(X_test)\n",
    "# Make Submission\n",
    "result = pd.DataFrame({\"Id\": test[\"Id\"], 'Sales': np.expm1(test_probs)})\n",
    "result.to_csv(\"rf_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Private Score - 0.166**  \n",
    "**Public Score - 0.151**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[features]\n",
    "y_train = np.log1p(train.Sales)\n",
    "X_test = test[features]\n",
    "#X_train, X_train_test, y_train, y_train_test = train_test_split(X, targets, test_size=0.20, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    }
   ],
   "source": [
    "kernels = ['rbf','poly']\n",
    "Cs = [0.1, 1, 10]\n",
    "gammas = [0.1, 1]\n",
    "param = {'C': Cs, 'gamma' : gammas, 'kernel' : kernels}\n",
    "\n",
    "sup_vec = SVR()\n",
    "gs = GridSearchCV(sup_vec, param_grid=param, scoring=scoring_fnc, cv=5, verbose=1, njobs = -1)\n",
    "gs.fit(X_train, y_train)\n",
    "svr_regr = gs.best_estimator_\n",
    "svr_regr.fit(X_train, y_train)\n",
    "scores = cross_val_score(svr_regr,X_train,y_train,cv=5,scoring=scoring_fnc)\n",
    "print(scores.mean())\n",
    "print(scores.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs=svr_regr.predict(X_test)\n",
    "# Make Submission\n",
    "result = pd.DataFrame({\"Id\": test[\"Id\"], 'Sales': np.expm1(test_probs)})\n",
    "result.to_csv(\"rf_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xgboost - with Train, Val and Test - Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid = train_test_split(train, test_size=0.2, random_state=10)\n",
    "y_train = np.log1p(X_train.Sales)\n",
    "y_valid = np.log1p(X_valid.Sales)\n",
    "dtrain = xgb.DMatrix(X_train[features], y_train)\n",
    "dvalid = xgb.DMatrix(X_valid[features], y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"objective\": \"reg:linear\",\n",
    "          \"booster\" : \"gbtree\",\n",
    "          \"eta\": 0.2,\n",
    "          \"max_depth\": 8,\n",
    "          \"subsample\": 0.9,\n",
    "          \"colsample_bytree\": 0.7,\n",
    "          \"silent\": 1,\n",
    "          \"seed\": 123\n",
    "          }\n",
    "num_boost_round = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runXGBCV(train_X, train_y, test_X, test_y = None):\n",
    "    model = GridSearchCV(\n",
    "        XGBRegressor(eta=0.2,objective='reg:linear', booster='gbtree', subsample=0.9, silent=1, seed=123, n),\n",
    "        {\n",
    "            'max_depth':[4,8,12],\n",
    "            'colsample_bytree':[0.4,0.8]\n",
    "        },cv=5, scoring=scoring_fnc)\n",
    "    model.fit(train_X, train_y)\n",
    "    print(model.best_params_, best_score_)\n",
    "    pred_test_y = model.best_estimator_.predict(test_X)\n",
    "    return pred_test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-4ae63bd3897b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpreds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrunXGBCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-26-9f969aeb0e9b>\u001b[0m in \u001b[0;36mrunXGBCV\u001b[1;34m(train_X, train_y, test_X, test_y)\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[1;34m'colsample_bytree'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         },cv=5, scoring=scoring_fnc)\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mpred_test_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 639\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set)\u001b[0m\n\u001b[0;32m    322\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m                               verbose_eval=verbose, xgb_model=xgb_model)\n\u001b[0m\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[0;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1019\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1020\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[1;32m-> 1021\u001b[1;33m                                                     dtrain.handle))\n\u001b[0m\u001b[0;32m   1022\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "preds=runXGBCV(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:6.61832\teval-rmse:6.6192\ttrain-rmspe:0.998705\teval-rmspe:0.998707\n",
      "Multiple eval metrics have been passed: 'eval-rmspe' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmspe hasn't improved in 100 rounds.\n",
      "[1]\ttrain-rmse:5.29883\teval-rmse:5.2997\ttrain-rmspe:0.994716\teval-rmspe:0.994726\n",
      "[2]\ttrain-rmse:4.2444\teval-rmse:4.24537\ttrain-rmspe:0.984559\teval-rmspe:0.984586\n",
      "[3]\ttrain-rmse:3.40154\teval-rmse:3.40247\ttrain-rmspe:0.964041\teval-rmspe:0.964093\n",
      "[4]\ttrain-rmse:2.7281\teval-rmse:2.72898\ttrain-rmspe:0.92963\teval-rmspe:0.929695\n",
      "[5]\ttrain-rmse:2.191\teval-rmse:2.19183\ttrain-rmspe:0.87991\teval-rmspe:0.879919\n",
      "[6]\ttrain-rmse:1.76333\teval-rmse:1.76415\ttrain-rmspe:0.816333\teval-rmspe:0.81612\n",
      "[7]\ttrain-rmse:1.42232\teval-rmse:1.42304\ttrain-rmspe:0.743026\teval-rmspe:0.742424\n",
      "[8]\ttrain-rmse:1.15202\teval-rmse:1.15273\ttrain-rmspe:0.665262\teval-rmspe:0.663852\n",
      "[9]\ttrain-rmse:0.938984\teval-rmse:0.93969\ttrain-rmspe:0.588598\teval-rmspe:0.585829\n",
      "[10]\ttrain-rmse:0.771353\teval-rmse:0.772012\ttrain-rmspe:0.517794\teval-rmspe:0.513036\n",
      "[11]\ttrain-rmse:0.641633\teval-rmse:0.642265\ttrain-rmspe:0.456598\teval-rmspe:0.44921\n",
      "[12]\ttrain-rmse:0.542489\teval-rmse:0.543174\ttrain-rmspe:0.407548\teval-rmspe:0.396836\n",
      "[13]\ttrain-rmse:0.467139\teval-rmse:0.46775\ttrain-rmspe:0.37029\teval-rmspe:0.356388\n",
      "[14]\ttrain-rmse:0.41094\teval-rmse:0.411518\ttrain-rmspe:0.344904\teval-rmspe:0.327241\n",
      "[15]\ttrain-rmse:0.370798\teval-rmse:0.37134\ttrain-rmspe:0.329601\teval-rmspe:0.308689\n",
      "[16]\ttrain-rmse:0.340724\teval-rmse:0.341246\ttrain-rmspe:0.321253\teval-rmspe:0.296866\n",
      "[17]\ttrain-rmse:0.316809\teval-rmse:0.31746\ttrain-rmspe:0.312171\teval-rmspe:0.287525\n",
      "[18]\ttrain-rmse:0.302637\teval-rmse:0.303294\ttrain-rmspe:0.311645\teval-rmspe:0.285323\n",
      "[19]\ttrain-rmse:0.290446\teval-rmse:0.291173\ttrain-rmspe:0.30982\teval-rmspe:0.282465\n",
      "[20]\ttrain-rmse:0.275935\teval-rmse:0.276556\ttrain-rmspe:0.30611\teval-rmspe:0.275735\n",
      "[21]\ttrain-rmse:0.269002\teval-rmse:0.269556\ttrain-rmspe:0.306364\teval-rmspe:0.27488\n",
      "[22]\ttrain-rmse:0.264225\teval-rmse:0.264753\ttrain-rmspe:0.306359\teval-rmspe:0.274051\n",
      "[23]\ttrain-rmse:0.260083\teval-rmse:0.260649\ttrain-rmspe:0.306435\teval-rmspe:0.273552\n",
      "[24]\ttrain-rmse:0.258488\teval-rmse:0.259079\ttrain-rmspe:0.308325\teval-rmspe:0.275155\n",
      "[25]\ttrain-rmse:0.25395\teval-rmse:0.254562\ttrain-rmspe:0.306876\teval-rmspe:0.273011\n",
      "[26]\ttrain-rmse:0.248214\teval-rmse:0.24879\ttrain-rmspe:0.303394\teval-rmspe:0.26848\n",
      "[27]\ttrain-rmse:0.244976\teval-rmse:0.245568\ttrain-rmspe:0.300516\teval-rmspe:0.266081\n",
      "[28]\ttrain-rmse:0.240145\teval-rmse:0.240759\ttrain-rmspe:0.297148\teval-rmspe:0.261848\n",
      "[29]\ttrain-rmse:0.238648\teval-rmse:0.239284\ttrain-rmspe:0.296758\teval-rmspe:0.261146\n",
      "[30]\ttrain-rmse:0.235837\teval-rmse:0.236428\ttrain-rmspe:0.294523\teval-rmspe:0.258525\n",
      "[31]\ttrain-rmse:0.231427\teval-rmse:0.232107\ttrain-rmspe:0.290541\teval-rmspe:0.254248\n",
      "[32]\ttrain-rmse:0.229978\teval-rmse:0.230739\ttrain-rmspe:0.287755\teval-rmspe:0.253194\n",
      "[33]\ttrain-rmse:0.226164\teval-rmse:0.227013\ttrain-rmspe:0.284046\teval-rmspe:0.24918\n",
      "[34]\ttrain-rmse:0.220133\teval-rmse:0.221027\ttrain-rmspe:0.278243\teval-rmspe:0.242975\n",
      "[35]\ttrain-rmse:0.216856\teval-rmse:0.217807\ttrain-rmspe:0.275453\teval-rmspe:0.239731\n",
      "[36]\ttrain-rmse:0.215922\teval-rmse:0.216907\ttrain-rmspe:0.274396\teval-rmspe:0.238644\n",
      "[37]\ttrain-rmse:0.215466\teval-rmse:0.216456\ttrain-rmspe:0.274426\teval-rmspe:0.238286\n",
      "[38]\ttrain-rmse:0.213929\teval-rmse:0.214971\ttrain-rmspe:0.273018\teval-rmspe:0.23669\n",
      "[39]\ttrain-rmse:0.212162\teval-rmse:0.213192\ttrain-rmspe:0.271816\teval-rmspe:0.234762\n",
      "[40]\ttrain-rmse:0.209995\teval-rmse:0.211079\ttrain-rmspe:0.269226\teval-rmspe:0.232374\n",
      "[41]\ttrain-rmse:0.209581\teval-rmse:0.210647\ttrain-rmspe:0.269061\teval-rmspe:0.231918\n",
      "[42]\ttrain-rmse:0.20919\teval-rmse:0.210272\ttrain-rmspe:0.267666\teval-rmspe:0.231566\n",
      "[43]\ttrain-rmse:0.206378\teval-rmse:0.207456\ttrain-rmspe:0.265632\teval-rmspe:0.228757\n",
      "[44]\ttrain-rmse:0.204793\teval-rmse:0.205904\ttrain-rmspe:0.264349\teval-rmspe:0.226966\n",
      "[45]\ttrain-rmse:0.202417\teval-rmse:0.203594\ttrain-rmspe:0.26197\teval-rmspe:0.224445\n",
      "[46]\ttrain-rmse:0.20219\teval-rmse:0.203368\ttrain-rmspe:0.261762\teval-rmspe:0.224209\n",
      "[47]\ttrain-rmse:0.201627\teval-rmse:0.202858\ttrain-rmspe:0.261239\teval-rmspe:0.223717\n",
      "[48]\ttrain-rmse:0.200193\teval-rmse:0.201461\ttrain-rmspe:0.260321\teval-rmspe:0.222239\n",
      "[49]\ttrain-rmse:0.199976\teval-rmse:0.201247\ttrain-rmspe:0.260234\teval-rmspe:0.222064\n",
      "[50]\ttrain-rmse:0.19718\teval-rmse:0.19852\ttrain-rmspe:0.257626\teval-rmspe:0.219051\n",
      "[51]\ttrain-rmse:0.194478\teval-rmse:0.195795\ttrain-rmspe:0.255135\teval-rmspe:0.216035\n",
      "[52]\ttrain-rmse:0.193742\teval-rmse:0.195069\ttrain-rmspe:0.254874\teval-rmspe:0.21524\n",
      "[53]\ttrain-rmse:0.190904\teval-rmse:0.192276\ttrain-rmspe:0.251819\teval-rmspe:0.212474\n",
      "[54]\ttrain-rmse:0.190116\teval-rmse:0.19154\ttrain-rmspe:0.250707\teval-rmspe:0.211708\n",
      "[55]\ttrain-rmse:0.187994\teval-rmse:0.189455\ttrain-rmspe:0.248708\teval-rmspe:0.209399\n",
      "[56]\ttrain-rmse:0.185677\teval-rmse:0.187227\ttrain-rmspe:0.246782\teval-rmspe:0.207201\n",
      "[57]\ttrain-rmse:0.18188\teval-rmse:0.183497\ttrain-rmspe:0.243449\teval-rmspe:0.202841\n",
      "[58]\ttrain-rmse:0.179762\teval-rmse:0.181415\ttrain-rmspe:0.240804\teval-rmspe:0.200616\n",
      "[59]\ttrain-rmse:0.179425\teval-rmse:0.1811\ttrain-rmspe:0.240528\teval-rmspe:0.200334\n",
      "[60]\ttrain-rmse:0.177597\teval-rmse:0.179288\ttrain-rmspe:0.238504\teval-rmspe:0.197972\n",
      "[61]\ttrain-rmse:0.177108\teval-rmse:0.178793\ttrain-rmspe:0.238125\teval-rmspe:0.197489\n",
      "[62]\ttrain-rmse:0.175649\teval-rmse:0.17738\ttrain-rmspe:0.236966\teval-rmspe:0.195991\n",
      "[63]\ttrain-rmse:0.174611\teval-rmse:0.176355\ttrain-rmspe:0.237135\teval-rmspe:0.194801\n",
      "[64]\ttrain-rmse:0.173927\teval-rmse:0.175689\ttrain-rmspe:0.236524\teval-rmspe:0.19409\n",
      "[65]\ttrain-rmse:0.171837\teval-rmse:0.173643\ttrain-rmspe:0.234636\teval-rmspe:0.191836\n",
      "[66]\ttrain-rmse:0.168637\teval-rmse:0.170506\ttrain-rmspe:0.231509\teval-rmspe:0.188115\n",
      "[67]\ttrain-rmse:0.167903\teval-rmse:0.169789\ttrain-rmspe:0.230117\teval-rmspe:0.187249\n",
      "[68]\ttrain-rmse:0.166449\teval-rmse:0.16834\ttrain-rmspe:0.228863\teval-rmspe:0.185721\n",
      "[69]\ttrain-rmse:0.165906\teval-rmse:0.167811\ttrain-rmspe:0.228485\teval-rmspe:0.18502\n",
      "[70]\ttrain-rmse:0.164632\teval-rmse:0.16658\ttrain-rmspe:0.227461\teval-rmspe:0.183663\n",
      "[71]\ttrain-rmse:0.164265\teval-rmse:0.166222\ttrain-rmspe:0.227413\teval-rmspe:0.183284\n",
      "[72]\ttrain-rmse:0.162099\teval-rmse:0.164104\ttrain-rmspe:0.225407\teval-rmspe:0.180784\n",
      "[73]\ttrain-rmse:0.160393\teval-rmse:0.162431\ttrain-rmspe:0.224008\teval-rmspe:0.179091\n",
      "[74]\ttrain-rmse:0.160059\teval-rmse:0.162112\ttrain-rmspe:0.217836\teval-rmspe:0.178741\n",
      "[75]\ttrain-rmse:0.158722\teval-rmse:0.160801\ttrain-rmspe:0.216661\teval-rmspe:0.177312\n",
      "[76]\ttrain-rmse:0.157267\teval-rmse:0.159418\ttrain-rmspe:0.215351\teval-rmspe:0.175761\n",
      "[77]\ttrain-rmse:0.155356\teval-rmse:0.157439\ttrain-rmspe:0.213852\teval-rmspe:0.173763\n",
      "[78]\ttrain-rmse:0.15422\teval-rmse:0.156326\ttrain-rmspe:0.21293\teval-rmspe:0.172625\n",
      "[79]\ttrain-rmse:0.153162\teval-rmse:0.155303\ttrain-rmspe:0.211767\teval-rmspe:0.171464\n",
      "[80]\ttrain-rmse:0.15263\teval-rmse:0.1548\ttrain-rmspe:0.211317\teval-rmspe:0.170898\n",
      "[81]\ttrain-rmse:0.150678\teval-rmse:0.152869\ttrain-rmspe:0.209815\teval-rmspe:0.168841\n",
      "[82]\ttrain-rmse:0.150548\teval-rmse:0.152754\ttrain-rmspe:0.209719\teval-rmspe:0.168732\n",
      "[83]\ttrain-rmse:0.150012\teval-rmse:0.152238\ttrain-rmspe:0.208803\teval-rmspe:0.168014\n",
      "[84]\ttrain-rmse:0.148933\teval-rmse:0.151168\ttrain-rmspe:0.207729\teval-rmspe:0.166649\n",
      "[85]\ttrain-rmse:0.14762\teval-rmse:0.149894\ttrain-rmspe:0.206701\teval-rmspe:0.165382\n",
      "[86]\ttrain-rmse:0.14733\teval-rmse:0.149633\ttrain-rmspe:0.206429\teval-rmspe:0.165118\n",
      "[87]\ttrain-rmse:0.146264\teval-rmse:0.148584\ttrain-rmspe:0.205581\teval-rmspe:0.164089\n",
      "[88]\ttrain-rmse:0.146115\teval-rmse:0.14846\ttrain-rmspe:0.204167\teval-rmspe:0.163939\n",
      "[89]\ttrain-rmse:0.145031\teval-rmse:0.147339\ttrain-rmspe:0.203256\teval-rmspe:0.162773\n",
      "[90]\ttrain-rmse:0.144351\teval-rmse:0.146673\ttrain-rmspe:0.202706\teval-rmspe:0.162083\n",
      "[91]\ttrain-rmse:0.143548\teval-rmse:0.145905\ttrain-rmspe:0.202053\teval-rmspe:0.161329\n",
      "[92]\ttrain-rmse:0.14289\teval-rmse:0.145283\ttrain-rmspe:0.20154\teval-rmspe:0.160695\n",
      "[93]\ttrain-rmse:0.142523\teval-rmse:0.144948\ttrain-rmspe:0.200276\teval-rmspe:0.160294\n",
      "[94]\ttrain-rmse:0.141576\teval-rmse:0.144036\ttrain-rmspe:0.199431\teval-rmspe:0.159232\n",
      "[95]\ttrain-rmse:0.140853\teval-rmse:0.143337\ttrain-rmspe:0.198369\teval-rmspe:0.158343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[96]\ttrain-rmse:0.140708\teval-rmse:0.143192\ttrain-rmspe:0.198507\teval-rmspe:0.158202\n",
      "[97]\ttrain-rmse:0.140282\teval-rmse:0.142826\ttrain-rmspe:0.198091\teval-rmspe:0.157687\n",
      "[98]\ttrain-rmse:0.139913\teval-rmse:0.142471\ttrain-rmspe:0.197802\teval-rmspe:0.157346\n",
      "[99]\ttrain-rmse:0.139166\teval-rmse:0.141721\ttrain-rmspe:0.197156\teval-rmspe:0.156576\n",
      "[100]\ttrain-rmse:0.138388\teval-rmse:0.140965\ttrain-rmspe:0.196143\teval-rmspe:0.155788\n",
      "[101]\ttrain-rmse:0.138142\teval-rmse:0.140724\ttrain-rmspe:0.195873\teval-rmspe:0.155531\n",
      "[102]\ttrain-rmse:0.137093\teval-rmse:0.139713\ttrain-rmspe:0.197605\teval-rmspe:0.154428\n",
      "[103]\ttrain-rmse:0.136637\teval-rmse:0.139274\ttrain-rmspe:0.197176\teval-rmspe:0.153967\n",
      "[104]\ttrain-rmse:0.136284\teval-rmse:0.138935\ttrain-rmspe:0.196856\teval-rmspe:0.153644\n",
      "[105]\ttrain-rmse:0.135941\teval-rmse:0.138623\ttrain-rmspe:0.196436\teval-rmspe:0.1533\n",
      "[106]\ttrain-rmse:0.135247\teval-rmse:0.137943\ttrain-rmspe:0.195925\teval-rmspe:0.152594\n",
      "[107]\ttrain-rmse:0.134986\teval-rmse:0.137713\ttrain-rmspe:0.195478\teval-rmspe:0.152279\n",
      "[108]\ttrain-rmse:0.134339\teval-rmse:0.137095\ttrain-rmspe:0.194769\teval-rmspe:0.151542\n",
      "[109]\ttrain-rmse:0.133445\teval-rmse:0.136218\ttrain-rmspe:0.194016\teval-rmspe:0.150576\n",
      "[110]\ttrain-rmse:0.133124\teval-rmse:0.13593\ttrain-rmspe:0.193824\teval-rmspe:0.150286\n",
      "[111]\ttrain-rmse:0.132615\teval-rmse:0.135437\ttrain-rmspe:0.193347\teval-rmspe:0.149783\n",
      "[112]\ttrain-rmse:0.131672\teval-rmse:0.134517\ttrain-rmspe:0.192323\teval-rmspe:0.148688\n",
      "[113]\ttrain-rmse:0.131215\teval-rmse:0.134067\ttrain-rmspe:0.192031\teval-rmspe:0.148225\n",
      "[114]\ttrain-rmse:0.130804\teval-rmse:0.133675\ttrain-rmspe:0.191407\teval-rmspe:0.14786\n",
      "[115]\ttrain-rmse:0.130676\teval-rmse:0.133557\ttrain-rmspe:0.191314\teval-rmspe:0.147741\n",
      "[116]\ttrain-rmse:0.130319\teval-rmse:0.133231\ttrain-rmspe:0.190943\teval-rmspe:0.147414\n",
      "[117]\ttrain-rmse:0.130027\teval-rmse:0.132956\ttrain-rmspe:0.190542\teval-rmspe:0.147135\n",
      "[118]\ttrain-rmse:0.129329\teval-rmse:0.132261\ttrain-rmspe:0.189634\teval-rmspe:0.146372\n",
      "[119]\ttrain-rmse:0.128994\teval-rmse:0.131919\ttrain-rmspe:0.189266\teval-rmspe:0.146009\n",
      "[120]\ttrain-rmse:0.128443\teval-rmse:0.131372\ttrain-rmspe:0.188575\teval-rmspe:0.145319\n",
      "[121]\ttrain-rmse:0.128229\teval-rmse:0.131201\ttrain-rmspe:0.188338\teval-rmspe:0.145125\n",
      "[122]\ttrain-rmse:0.127842\teval-rmse:0.130839\ttrain-rmspe:0.18796\teval-rmspe:0.144756\n",
      "[123]\ttrain-rmse:0.127225\teval-rmse:0.130225\ttrain-rmspe:0.187569\teval-rmspe:0.144096\n",
      "[124]\ttrain-rmse:0.12683\teval-rmse:0.129844\ttrain-rmspe:0.187294\teval-rmspe:0.143746\n",
      "[125]\ttrain-rmse:0.126514\teval-rmse:0.129541\ttrain-rmspe:0.187058\teval-rmspe:0.14345\n",
      "[126]\ttrain-rmse:0.12624\teval-rmse:0.129285\ttrain-rmspe:0.186904\teval-rmspe:0.143197\n",
      "[127]\ttrain-rmse:0.125423\teval-rmse:0.128454\ttrain-rmspe:0.186157\teval-rmspe:0.142136\n",
      "[128]\ttrain-rmse:0.125222\teval-rmse:0.128281\ttrain-rmspe:0.186011\teval-rmspe:0.141967\n",
      "[129]\ttrain-rmse:0.124694\teval-rmse:0.127739\ttrain-rmspe:0.185276\teval-rmspe:0.141273\n",
      "[130]\ttrain-rmse:0.123932\teval-rmse:0.126975\ttrain-rmspe:0.18457\teval-rmspe:0.14046\n",
      "[131]\ttrain-rmse:0.123509\teval-rmse:0.126572\ttrain-rmspe:0.184036\teval-rmspe:0.140065\n",
      "[132]\ttrain-rmse:0.122922\teval-rmse:0.125997\ttrain-rmspe:0.183535\teval-rmspe:0.139472\n",
      "[133]\ttrain-rmse:0.122549\teval-rmse:0.125629\ttrain-rmspe:0.183308\teval-rmspe:0.139119\n",
      "[134]\ttrain-rmse:0.122249\teval-rmse:0.125347\ttrain-rmspe:0.183062\teval-rmspe:0.138783\n",
      "[135]\ttrain-rmse:0.121972\teval-rmse:0.12508\ttrain-rmspe:0.182858\teval-rmspe:0.138445\n",
      "[136]\ttrain-rmse:0.121628\teval-rmse:0.124752\ttrain-rmspe:0.182486\teval-rmspe:0.138077\n",
      "[137]\ttrain-rmse:0.121424\teval-rmse:0.124545\ttrain-rmspe:0.182266\teval-rmspe:0.137862\n",
      "[138]\ttrain-rmse:0.120916\teval-rmse:0.124028\ttrain-rmspe:0.181818\teval-rmspe:0.137295\n",
      "[139]\ttrain-rmse:0.12078\teval-rmse:0.123909\ttrain-rmspe:0.181707\teval-rmspe:0.137185\n",
      "[140]\ttrain-rmse:0.12053\teval-rmse:0.123693\ttrain-rmspe:0.181483\teval-rmspe:0.136964\n",
      "[141]\ttrain-rmse:0.120251\teval-rmse:0.123425\ttrain-rmspe:0.180668\teval-rmspe:0.136434\n",
      "[142]\ttrain-rmse:0.120001\teval-rmse:0.123182\ttrain-rmspe:0.180464\teval-rmspe:0.136155\n",
      "[143]\ttrain-rmse:0.119654\teval-rmse:0.122839\ttrain-rmspe:0.180152\teval-rmspe:0.135731\n",
      "[144]\ttrain-rmse:0.11953\teval-rmse:0.122735\ttrain-rmspe:0.180083\teval-rmspe:0.135647\n",
      "[145]\ttrain-rmse:0.119025\teval-rmse:0.122241\ttrain-rmspe:0.179601\teval-rmspe:0.135122\n",
      "[146]\ttrain-rmse:0.118431\teval-rmse:0.121658\ttrain-rmspe:0.179111\teval-rmspe:0.134447\n",
      "[147]\ttrain-rmse:0.118264\teval-rmse:0.121513\ttrain-rmspe:0.178986\teval-rmspe:0.134303\n",
      "[148]\ttrain-rmse:0.117991\teval-rmse:0.121248\ttrain-rmspe:0.178703\teval-rmspe:0.134036\n",
      "[149]\ttrain-rmse:0.117794\teval-rmse:0.121048\ttrain-rmspe:0.178518\teval-rmspe:0.133807\n",
      "[150]\ttrain-rmse:0.117548\teval-rmse:0.120817\ttrain-rmspe:0.178288\teval-rmspe:0.133527\n",
      "[151]\ttrain-rmse:0.11717\teval-rmse:0.120471\ttrain-rmspe:0.173931\teval-rmspe:0.133074\n",
      "[152]\ttrain-rmse:0.11685\teval-rmse:0.120168\ttrain-rmspe:0.173669\teval-rmspe:0.132729\n",
      "[153]\ttrain-rmse:0.116704\teval-rmse:0.120041\ttrain-rmspe:0.173583\teval-rmspe:0.1326\n",
      "[154]\ttrain-rmse:0.116647\teval-rmse:0.119996\ttrain-rmspe:0.173547\teval-rmspe:0.13255\n",
      "[155]\ttrain-rmse:0.116448\teval-rmse:0.119818\ttrain-rmspe:0.174312\teval-rmspe:0.13238\n",
      "[156]\ttrain-rmse:0.116332\teval-rmse:0.119708\ttrain-rmspe:0.174209\teval-rmspe:0.132267\n",
      "[157]\ttrain-rmse:0.115865\teval-rmse:0.119248\ttrain-rmspe:0.173947\teval-rmspe:0.13178\n",
      "[158]\ttrain-rmse:0.115644\teval-rmse:0.119056\ttrain-rmspe:0.17354\teval-rmspe:0.13156\n",
      "[159]\ttrain-rmse:0.115532\teval-rmse:0.118967\ttrain-rmspe:0.173326\teval-rmspe:0.13145\n",
      "[160]\ttrain-rmse:0.115368\teval-rmse:0.118823\ttrain-rmspe:0.173178\teval-rmspe:0.131311\n",
      "[161]\ttrain-rmse:0.115299\teval-rmse:0.118777\ttrain-rmspe:0.173114\teval-rmspe:0.131269\n",
      "[162]\ttrain-rmse:0.115047\teval-rmse:0.118548\ttrain-rmspe:0.172909\teval-rmspe:0.131069\n",
      "[163]\ttrain-rmse:0.11483\teval-rmse:0.118335\ttrain-rmspe:0.172614\teval-rmspe:0.130849\n",
      "[164]\ttrain-rmse:0.114709\teval-rmse:0.118237\ttrain-rmspe:0.172542\teval-rmspe:0.130776\n",
      "[165]\ttrain-rmse:0.114493\teval-rmse:0.118044\ttrain-rmspe:0.17238\teval-rmspe:0.130588\n",
      "[166]\ttrain-rmse:0.114392\teval-rmse:0.117957\ttrain-rmspe:0.172296\teval-rmspe:0.130505\n",
      "[167]\ttrain-rmse:0.114263\teval-rmse:0.117849\ttrain-rmspe:0.172112\teval-rmspe:0.130368\n",
      "[168]\ttrain-rmse:0.114138\teval-rmse:0.117728\ttrain-rmspe:0.171976\teval-rmspe:0.130235\n",
      "[169]\ttrain-rmse:0.11396\teval-rmse:0.117576\ttrain-rmspe:0.171586\teval-rmspe:0.130072\n",
      "[170]\ttrain-rmse:0.11377\teval-rmse:0.117398\ttrain-rmspe:0.171415\teval-rmspe:0.12988\n",
      "[171]\ttrain-rmse:0.11343\teval-rmse:0.117055\ttrain-rmspe:0.171169\teval-rmspe:0.129549\n",
      "[172]\ttrain-rmse:0.113285\teval-rmse:0.116917\ttrain-rmspe:0.171069\teval-rmspe:0.129408\n",
      "[173]\ttrain-rmse:0.113206\teval-rmse:0.11685\ttrain-rmspe:0.171011\teval-rmspe:0.129344\n",
      "[174]\ttrain-rmse:0.113137\teval-rmse:0.116801\ttrain-rmspe:0.17097\teval-rmspe:0.129297\n",
      "[175]\ttrain-rmse:0.113013\teval-rmse:0.116698\ttrain-rmspe:0.170803\teval-rmspe:0.129196\n",
      "[176]\ttrain-rmse:0.112919\teval-rmse:0.116611\ttrain-rmspe:0.170689\teval-rmspe:0.129106\n",
      "[177]\ttrain-rmse:0.112674\teval-rmse:0.116392\ttrain-rmspe:0.169887\teval-rmspe:0.12888\n",
      "[178]\ttrain-rmse:0.11252\teval-rmse:0.116268\ttrain-rmspe:0.169732\teval-rmspe:0.128739\n",
      "[179]\ttrain-rmse:0.112415\teval-rmse:0.116187\ttrain-rmspe:0.169636\teval-rmspe:0.12866\n",
      "[180]\ttrain-rmse:0.112213\teval-rmse:0.116009\ttrain-rmspe:0.169455\teval-rmspe:0.128455\n",
      "[181]\ttrain-rmse:0.11206\teval-rmse:0.115872\ttrain-rmspe:0.169324\teval-rmspe:0.12831\n",
      "[182]\ttrain-rmse:0.111762\teval-rmse:0.11558\ttrain-rmspe:0.169082\teval-rmspe:0.127983\n",
      "[183]\ttrain-rmse:0.111687\teval-rmse:0.11551\ttrain-rmspe:0.169061\teval-rmspe:0.127908\n",
      "[184]\ttrain-rmse:0.111611\teval-rmse:0.115449\ttrain-rmspe:0.169\teval-rmspe:0.127848\n",
      "[185]\ttrain-rmse:0.111498\teval-rmse:0.115355\ttrain-rmspe:0.168906\teval-rmspe:0.127734\n",
      "[186]\ttrain-rmse:0.111387\teval-rmse:0.115269\ttrain-rmspe:0.168796\teval-rmspe:0.127653\n",
      "[187]\ttrain-rmse:0.11116\teval-rmse:0.115042\ttrain-rmspe:0.16864\teval-rmspe:0.127388\n",
      "[188]\ttrain-rmse:0.110751\teval-rmse:0.114627\ttrain-rmspe:0.168234\teval-rmspe:0.126944\n",
      "[189]\ttrain-rmse:0.110573\teval-rmse:0.114471\ttrain-rmspe:0.168095\teval-rmspe:0.126782\n",
      "[190]\ttrain-rmse:0.110475\teval-rmse:0.114392\ttrain-rmspe:0.167957\teval-rmspe:0.126679\n",
      "[191]\ttrain-rmse:0.110293\teval-rmse:0.114219\ttrain-rmspe:0.167855\teval-rmspe:0.126496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[192]\ttrain-rmse:0.110113\teval-rmse:0.114061\ttrain-rmspe:0.167672\teval-rmspe:0.126308\n",
      "[193]\ttrain-rmse:0.10995\teval-rmse:0.11392\ttrain-rmspe:0.167658\teval-rmspe:0.126151\n",
      "[194]\ttrain-rmse:0.10989\teval-rmse:0.113869\ttrain-rmspe:0.167562\teval-rmspe:0.126088\n",
      "[195]\ttrain-rmse:0.109842\teval-rmse:0.113833\ttrain-rmspe:0.167524\teval-rmspe:0.126054\n",
      "[196]\ttrain-rmse:0.109654\teval-rmse:0.113662\ttrain-rmspe:0.167156\teval-rmspe:0.125837\n",
      "[197]\ttrain-rmse:0.109493\teval-rmse:0.113525\ttrain-rmspe:0.166877\teval-rmspe:0.125682\n",
      "[198]\ttrain-rmse:0.109336\teval-rmse:0.113377\ttrain-rmspe:0.166748\teval-rmspe:0.125519\n",
      "[199]\ttrain-rmse:0.109243\teval-rmse:0.113301\ttrain-rmspe:0.166639\teval-rmspe:0.125428\n",
      "[200]\ttrain-rmse:0.109092\teval-rmse:0.11317\ttrain-rmspe:0.166333\teval-rmspe:0.125281\n",
      "[201]\ttrain-rmse:0.108878\teval-rmse:0.112979\ttrain-rmspe:0.166578\teval-rmspe:0.125061\n",
      "[202]\ttrain-rmse:0.108756\teval-rmse:0.112887\ttrain-rmspe:0.166483\teval-rmspe:0.124975\n",
      "[203]\ttrain-rmse:0.108601\teval-rmse:0.112772\ttrain-rmspe:0.165845\teval-rmspe:0.124854\n",
      "[204]\ttrain-rmse:0.1083\teval-rmse:0.112475\ttrain-rmspe:0.165614\teval-rmspe:0.12455\n",
      "[205]\ttrain-rmse:0.107923\teval-rmse:0.112102\ttrain-rmspe:0.165339\teval-rmspe:0.124173\n",
      "[206]\ttrain-rmse:0.107836\teval-rmse:0.112037\ttrain-rmspe:0.165319\teval-rmspe:0.124104\n",
      "[207]\ttrain-rmse:0.107574\teval-rmse:0.111826\ttrain-rmspe:0.164973\teval-rmspe:0.123869\n",
      "[208]\ttrain-rmse:0.107351\teval-rmse:0.111613\ttrain-rmspe:0.164503\teval-rmspe:0.123524\n",
      "[209]\ttrain-rmse:0.107263\teval-rmse:0.111546\ttrain-rmspe:0.164452\teval-rmspe:0.123462\n",
      "[210]\ttrain-rmse:0.107172\teval-rmse:0.111474\ttrain-rmspe:0.164374\teval-rmspe:0.123387\n",
      "[211]\ttrain-rmse:0.107054\teval-rmse:0.111381\ttrain-rmspe:0.164109\teval-rmspe:0.123076\n",
      "[212]\ttrain-rmse:0.106935\teval-rmse:0.111273\ttrain-rmspe:0.164039\teval-rmspe:0.122963\n",
      "[213]\ttrain-rmse:0.106839\teval-rmse:0.111202\ttrain-rmspe:0.163948\teval-rmspe:0.122902\n",
      "[214]\ttrain-rmse:0.106669\teval-rmse:0.111039\ttrain-rmspe:0.163728\teval-rmspe:0.122704\n",
      "[215]\ttrain-rmse:0.106584\teval-rmse:0.110969\ttrain-rmspe:0.163899\teval-rmspe:0.122622\n",
      "[216]\ttrain-rmse:0.10648\teval-rmse:0.110898\ttrain-rmspe:0.157094\teval-rmspe:0.122556\n",
      "[217]\ttrain-rmse:0.106425\teval-rmse:0.110851\ttrain-rmspe:0.157054\teval-rmspe:0.122517\n",
      "[218]\ttrain-rmse:0.106187\teval-rmse:0.110618\ttrain-rmspe:0.156897\teval-rmspe:0.12228\n",
      "[219]\ttrain-rmse:0.106038\teval-rmse:0.1105\ttrain-rmspe:0.156847\teval-rmspe:0.122115\n",
      "[220]\ttrain-rmse:0.106008\teval-rmse:0.110473\ttrain-rmspe:0.156839\teval-rmspe:0.122091\n",
      "[221]\ttrain-rmse:0.105889\teval-rmse:0.11038\ttrain-rmspe:0.156752\teval-rmspe:0.122005\n",
      "[222]\ttrain-rmse:0.105649\teval-rmse:0.110141\ttrain-rmspe:0.156545\teval-rmspe:0.121724\n",
      "[223]\ttrain-rmse:0.105478\teval-rmse:0.109979\ttrain-rmspe:0.156409\teval-rmspe:0.121568\n",
      "[224]\ttrain-rmse:0.105337\teval-rmse:0.109838\ttrain-rmspe:0.156295\teval-rmspe:0.121416\n",
      "[225]\ttrain-rmse:0.105251\teval-rmse:0.109772\ttrain-rmspe:0.156224\teval-rmspe:0.121385\n",
      "[226]\ttrain-rmse:0.105222\teval-rmse:0.109753\ttrain-rmspe:0.156161\teval-rmspe:0.121367\n",
      "[227]\ttrain-rmse:0.105092\teval-rmse:0.109645\ttrain-rmspe:0.155889\teval-rmspe:0.121261\n",
      "[228]\ttrain-rmse:0.104939\teval-rmse:0.109501\ttrain-rmspe:0.155776\teval-rmspe:0.121111\n",
      "[229]\ttrain-rmse:0.104781\teval-rmse:0.109363\ttrain-rmspe:0.155675\teval-rmspe:0.120981\n",
      "[230]\ttrain-rmse:0.104676\teval-rmse:0.109263\ttrain-rmspe:0.155582\teval-rmspe:0.120839\n",
      "[231]\ttrain-rmse:0.104499\teval-rmse:0.109103\ttrain-rmspe:0.155715\teval-rmspe:0.120628\n",
      "[232]\ttrain-rmse:0.104392\teval-rmse:0.10901\ttrain-rmspe:0.155689\teval-rmspe:0.120532\n",
      "[233]\ttrain-rmse:0.104213\teval-rmse:0.108857\ttrain-rmspe:0.155455\teval-rmspe:0.120399\n",
      "[234]\ttrain-rmse:0.104106\teval-rmse:0.108762\ttrain-rmspe:0.155294\teval-rmspe:0.120281\n",
      "[235]\ttrain-rmse:0.103985\teval-rmse:0.108663\ttrain-rmspe:0.155186\teval-rmspe:0.120169\n",
      "[236]\ttrain-rmse:0.103909\teval-rmse:0.108609\ttrain-rmspe:0.155128\teval-rmspe:0.120107\n",
      "[237]\ttrain-rmse:0.103859\teval-rmse:0.108578\ttrain-rmspe:0.155094\teval-rmspe:0.120085\n",
      "[238]\ttrain-rmse:0.103791\teval-rmse:0.108524\ttrain-rmspe:0.155051\teval-rmspe:0.120032\n",
      "[239]\ttrain-rmse:0.103598\teval-rmse:0.108355\ttrain-rmspe:0.154916\teval-rmspe:0.119836\n",
      "[240]\ttrain-rmse:0.103465\teval-rmse:0.108249\ttrain-rmspe:0.154818\teval-rmspe:0.119743\n",
      "[241]\ttrain-rmse:0.103349\teval-rmse:0.10814\ttrain-rmspe:0.15469\teval-rmspe:0.119625\n",
      "[242]\ttrain-rmse:0.103222\teval-rmse:0.108019\ttrain-rmspe:0.154591\teval-rmspe:0.119507\n",
      "[243]\ttrain-rmse:0.103182\teval-rmse:0.107992\ttrain-rmspe:0.154561\teval-rmspe:0.119494\n",
      "[244]\ttrain-rmse:0.103086\teval-rmse:0.10792\ttrain-rmspe:0.154485\teval-rmspe:0.119426\n",
      "[245]\ttrain-rmse:0.102964\teval-rmse:0.107806\ttrain-rmspe:0.154405\teval-rmspe:0.119313\n",
      "[246]\ttrain-rmse:0.1029\teval-rmse:0.107761\ttrain-rmspe:0.154304\teval-rmspe:0.119271\n",
      "[247]\ttrain-rmse:0.102879\teval-rmse:0.107751\ttrain-rmspe:0.154286\teval-rmspe:0.119261\n",
      "[248]\ttrain-rmse:0.102793\teval-rmse:0.107697\ttrain-rmspe:0.154175\teval-rmspe:0.119215\n",
      "[249]\ttrain-rmse:0.102679\teval-rmse:0.107593\ttrain-rmspe:0.154092\teval-rmspe:0.11911\n",
      "[250]\ttrain-rmse:0.102548\teval-rmse:0.107485\ttrain-rmspe:0.15398\teval-rmspe:0.118996\n",
      "[251]\ttrain-rmse:0.102479\teval-rmse:0.107431\ttrain-rmspe:0.153928\teval-rmspe:0.118935\n",
      "[252]\ttrain-rmse:0.102387\teval-rmse:0.107369\ttrain-rmspe:0.153504\teval-rmspe:0.118852\n",
      "[253]\ttrain-rmse:0.10227\teval-rmse:0.107266\ttrain-rmspe:0.153264\teval-rmspe:0.118757\n",
      "[254]\ttrain-rmse:0.102068\teval-rmse:0.10708\ttrain-rmspe:0.15318\teval-rmspe:0.118575\n",
      "[255]\ttrain-rmse:0.101976\teval-rmse:0.107001\ttrain-rmspe:0.152672\teval-rmspe:0.118501\n",
      "[256]\ttrain-rmse:0.10188\teval-rmse:0.106926\ttrain-rmspe:0.152596\teval-rmspe:0.118423\n",
      "[257]\ttrain-rmse:0.101758\teval-rmse:0.106829\ttrain-rmspe:0.152496\teval-rmspe:0.118304\n",
      "[258]\ttrain-rmse:0.101683\teval-rmse:0.106765\ttrain-rmspe:0.152447\teval-rmspe:0.118239\n",
      "[259]\ttrain-rmse:0.101608\teval-rmse:0.106706\ttrain-rmspe:0.15239\teval-rmspe:0.118179\n",
      "[260]\ttrain-rmse:0.101535\teval-rmse:0.106643\ttrain-rmspe:0.15235\teval-rmspe:0.11812\n",
      "[261]\ttrain-rmse:0.101429\teval-rmse:0.106543\ttrain-rmspe:0.15198\teval-rmspe:0.117922\n",
      "[262]\ttrain-rmse:0.101332\teval-rmse:0.106462\ttrain-rmspe:0.151789\teval-rmspe:0.11785\n",
      "[263]\ttrain-rmse:0.101218\teval-rmse:0.106372\ttrain-rmspe:0.151692\teval-rmspe:0.117738\n",
      "[264]\ttrain-rmse:0.10117\teval-rmse:0.106344\ttrain-rmspe:0.151638\teval-rmspe:0.11771\n",
      "[265]\ttrain-rmse:0.100993\teval-rmse:0.10617\ttrain-rmspe:0.151498\teval-rmspe:0.11753\n",
      "[266]\ttrain-rmse:0.100935\teval-rmse:0.106128\ttrain-rmspe:0.151461\teval-rmspe:0.117479\n",
      "[267]\ttrain-rmse:0.100847\teval-rmse:0.106069\ttrain-rmspe:0.151353\teval-rmspe:0.117412\n",
      "[268]\ttrain-rmse:0.100761\teval-rmse:0.105992\ttrain-rmspe:0.151292\teval-rmspe:0.117338\n",
      "[269]\ttrain-rmse:0.100681\teval-rmse:0.105932\ttrain-rmspe:0.151236\teval-rmspe:0.117273\n",
      "[270]\ttrain-rmse:0.100609\teval-rmse:0.105885\ttrain-rmspe:0.151185\teval-rmspe:0.117236\n",
      "[271]\ttrain-rmse:0.100454\teval-rmse:0.10575\ttrain-rmspe:0.151086\teval-rmspe:0.117106\n",
      "[272]\ttrain-rmse:0.100303\teval-rmse:0.10562\ttrain-rmspe:0.151005\teval-rmspe:0.116974\n",
      "[273]\ttrain-rmse:0.10025\teval-rmse:0.105582\ttrain-rmspe:0.150943\teval-rmspe:0.116935\n",
      "[274]\ttrain-rmse:0.100125\teval-rmse:0.105479\ttrain-rmspe:0.15077\teval-rmspe:0.11684\n",
      "[275]\ttrain-rmse:0.09998\teval-rmse:0.105357\ttrain-rmspe:0.150636\teval-rmspe:0.116719\n",
      "[276]\ttrain-rmse:0.099868\teval-rmse:0.105269\ttrain-rmspe:0.150605\teval-rmspe:0.116636\n",
      "[277]\ttrain-rmse:0.0998\teval-rmse:0.10521\ttrain-rmspe:0.150595\teval-rmspe:0.116579\n",
      "[278]\ttrain-rmse:0.099778\teval-rmse:0.105201\ttrain-rmspe:0.150569\teval-rmspe:0.116568\n",
      "[279]\ttrain-rmse:0.099674\teval-rmse:0.105127\ttrain-rmspe:0.150241\teval-rmspe:0.116442\n",
      "[280]\ttrain-rmse:0.099595\teval-rmse:0.105073\ttrain-rmspe:0.150181\teval-rmspe:0.116396\n",
      "[281]\ttrain-rmse:0.099537\teval-rmse:0.105039\ttrain-rmspe:0.150123\teval-rmspe:0.116359\n",
      "[282]\ttrain-rmse:0.099511\teval-rmse:0.10502\ttrain-rmspe:0.150107\teval-rmspe:0.116347\n",
      "[283]\ttrain-rmse:0.099444\teval-rmse:0.104975\ttrain-rmspe:0.150014\teval-rmspe:0.116295\n",
      "[284]\ttrain-rmse:0.09941\teval-rmse:0.104956\ttrain-rmspe:0.149986\teval-rmspe:0.116274\n",
      "[285]\ttrain-rmse:0.099364\teval-rmse:0.104929\ttrain-rmspe:0.149682\teval-rmspe:0.116245\n",
      "[286]\ttrain-rmse:0.09929\teval-rmse:0.104873\ttrain-rmspe:0.149616\teval-rmspe:0.116188\n",
      "[287]\ttrain-rmse:0.099219\teval-rmse:0.104816\ttrain-rmspe:0.149568\teval-rmspe:0.116135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[288]\ttrain-rmse:0.099161\teval-rmse:0.10478\ttrain-rmspe:0.149419\teval-rmspe:0.116102\n",
      "[289]\ttrain-rmse:0.09899\teval-rmse:0.10462\ttrain-rmspe:0.149224\teval-rmspe:0.115932\n",
      "[290]\ttrain-rmse:0.098932\teval-rmse:0.104578\ttrain-rmspe:0.14916\teval-rmspe:0.115883\n",
      "[291]\ttrain-rmse:0.098833\teval-rmse:0.104499\ttrain-rmspe:0.149078\teval-rmspe:0.1158\n",
      "[292]\ttrain-rmse:0.098792\teval-rmse:0.104468\ttrain-rmspe:0.149058\teval-rmspe:0.115775\n",
      "[293]\ttrain-rmse:0.098771\teval-rmse:0.104451\ttrain-rmspe:0.14904\teval-rmspe:0.115755\n",
      "[294]\ttrain-rmse:0.098662\teval-rmse:0.104364\ttrain-rmspe:0.148959\teval-rmspe:0.115671\n",
      "[295]\ttrain-rmse:0.098572\teval-rmse:0.104302\ttrain-rmspe:0.142074\teval-rmspe:0.115611\n",
      "[296]\ttrain-rmse:0.098521\teval-rmse:0.104275\ttrain-rmspe:0.14204\teval-rmspe:0.115589\n",
      "[297]\ttrain-rmse:0.098372\teval-rmse:0.104133\ttrain-rmspe:0.141974\teval-rmspe:0.115434\n",
      "[298]\ttrain-rmse:0.098289\teval-rmse:0.104075\ttrain-rmspe:0.141902\teval-rmspe:0.115388\n",
      "[299]\ttrain-rmse:0.098162\teval-rmse:0.103973\ttrain-rmspe:0.14181\teval-rmspe:0.11529\n",
      "[300]\ttrain-rmse:0.098045\teval-rmse:0.103874\ttrain-rmspe:0.141607\teval-rmspe:0.115192\n",
      "[301]\ttrain-rmse:0.097959\teval-rmse:0.103808\ttrain-rmspe:0.14132\teval-rmspe:0.115128\n",
      "[302]\ttrain-rmse:0.09781\teval-rmse:0.103679\ttrain-rmspe:0.136812\teval-rmspe:0.115007\n",
      "[303]\ttrain-rmse:0.09775\teval-rmse:0.103637\ttrain-rmspe:0.136726\teval-rmspe:0.114973\n",
      "[304]\ttrain-rmse:0.097656\teval-rmse:0.103568\ttrain-rmspe:0.136645\teval-rmspe:0.11491\n",
      "[305]\ttrain-rmse:0.09758\teval-rmse:0.103517\ttrain-rmspe:0.136577\teval-rmspe:0.11485\n",
      "[306]\ttrain-rmse:0.097493\teval-rmse:0.103446\ttrain-rmspe:0.136458\teval-rmspe:0.114745\n",
      "[307]\ttrain-rmse:0.097348\teval-rmse:0.103307\ttrain-rmspe:0.136348\teval-rmspe:0.114626\n",
      "[308]\ttrain-rmse:0.097284\teval-rmse:0.103253\ttrain-rmspe:0.136299\teval-rmspe:0.114573\n",
      "[309]\ttrain-rmse:0.097108\teval-rmse:0.103088\ttrain-rmspe:0.136067\teval-rmspe:0.114385\n",
      "[310]\ttrain-rmse:0.09697\teval-rmse:0.102969\ttrain-rmspe:0.136104\teval-rmspe:0.114269\n",
      "[311]\ttrain-rmse:0.096925\teval-rmse:0.102941\ttrain-rmspe:0.136066\teval-rmspe:0.114244\n",
      "[312]\ttrain-rmse:0.096876\teval-rmse:0.102911\ttrain-rmspe:0.136024\teval-rmspe:0.114216\n",
      "[313]\ttrain-rmse:0.096822\teval-rmse:0.102869\ttrain-rmspe:0.135987\teval-rmspe:0.114176\n",
      "[314]\ttrain-rmse:0.096755\teval-rmse:0.102825\ttrain-rmspe:0.135844\teval-rmspe:0.114121\n",
      "[315]\ttrain-rmse:0.096739\teval-rmse:0.102816\ttrain-rmspe:0.135801\teval-rmspe:0.114108\n",
      "[316]\ttrain-rmse:0.09666\teval-rmse:0.102749\ttrain-rmspe:0.135705\teval-rmspe:0.114052\n",
      "[317]\ttrain-rmse:0.096577\teval-rmse:0.102688\ttrain-rmspe:0.135642\teval-rmspe:0.113996\n",
      "[318]\ttrain-rmse:0.096516\teval-rmse:0.102642\ttrain-rmspe:0.135589\teval-rmspe:0.113948\n",
      "[319]\ttrain-rmse:0.096468\teval-rmse:0.102615\ttrain-rmspe:0.13555\teval-rmspe:0.113921\n",
      "[320]\ttrain-rmse:0.096414\teval-rmse:0.102572\ttrain-rmspe:0.135482\teval-rmspe:0.113882\n",
      "[321]\ttrain-rmse:0.096386\teval-rmse:0.102558\ttrain-rmspe:0.135457\teval-rmspe:0.113871\n",
      "[322]\ttrain-rmse:0.096247\teval-rmse:0.102423\ttrain-rmspe:0.13535\teval-rmspe:0.113735\n",
      "[323]\ttrain-rmse:0.096181\teval-rmse:0.102367\ttrain-rmspe:0.135186\teval-rmspe:0.113673\n",
      "[324]\ttrain-rmse:0.096064\teval-rmse:0.102262\ttrain-rmspe:0.135086\teval-rmspe:0.113577\n",
      "[325]\ttrain-rmse:0.096021\teval-rmse:0.102235\ttrain-rmspe:0.135075\teval-rmspe:0.113554\n",
      "[326]\ttrain-rmse:0.095882\teval-rmse:0.102106\ttrain-rmspe:0.134915\teval-rmspe:0.113421\n",
      "[327]\ttrain-rmse:0.095842\teval-rmse:0.102077\ttrain-rmspe:0.134875\teval-rmspe:0.11339\n",
      "[328]\ttrain-rmse:0.095793\teval-rmse:0.102039\ttrain-rmspe:0.134793\teval-rmspe:0.113352\n",
      "[329]\ttrain-rmse:0.09576\teval-rmse:0.102021\ttrain-rmspe:0.134765\teval-rmspe:0.113337\n",
      "[330]\ttrain-rmse:0.095716\teval-rmse:0.101992\ttrain-rmspe:0.134727\teval-rmspe:0.113309\n",
      "[331]\ttrain-rmse:0.095671\teval-rmse:0.10196\ttrain-rmspe:0.134696\teval-rmspe:0.113287\n",
      "[332]\ttrain-rmse:0.095634\teval-rmse:0.101928\ttrain-rmspe:0.13467\teval-rmspe:0.113254\n",
      "[333]\ttrain-rmse:0.095551\teval-rmse:0.101857\ttrain-rmspe:0.134582\teval-rmspe:0.113188\n",
      "[334]\ttrain-rmse:0.095497\teval-rmse:0.101816\ttrain-rmspe:0.134534\teval-rmspe:0.113147\n",
      "[335]\ttrain-rmse:0.095453\teval-rmse:0.101792\ttrain-rmspe:0.134299\teval-rmspe:0.113124\n",
      "[336]\ttrain-rmse:0.095383\teval-rmse:0.101736\ttrain-rmspe:0.134236\teval-rmspe:0.113072\n",
      "[337]\ttrain-rmse:0.095307\teval-rmse:0.101681\ttrain-rmspe:0.134184\teval-rmspe:0.113021\n",
      "[338]\ttrain-rmse:0.095267\teval-rmse:0.10165\ttrain-rmspe:0.134141\teval-rmspe:0.112989\n",
      "[339]\ttrain-rmse:0.095231\teval-rmse:0.101627\ttrain-rmspe:0.134101\teval-rmspe:0.112963\n",
      "[340]\ttrain-rmse:0.095177\teval-rmse:0.101596\ttrain-rmspe:0.134037\teval-rmspe:0.112938\n",
      "[341]\ttrain-rmse:0.095094\teval-rmse:0.101543\ttrain-rmspe:0.133881\teval-rmspe:0.112859\n",
      "[342]\ttrain-rmse:0.095068\teval-rmse:0.101527\ttrain-rmspe:0.133863\teval-rmspe:0.112845\n",
      "[343]\ttrain-rmse:0.095005\teval-rmse:0.10148\ttrain-rmspe:0.133792\teval-rmspe:0.112804\n",
      "[344]\ttrain-rmse:0.094969\teval-rmse:0.101464\ttrain-rmspe:0.133761\teval-rmspe:0.112792\n",
      "[345]\ttrain-rmse:0.094895\teval-rmse:0.101407\ttrain-rmspe:0.133631\teval-rmspe:0.112736\n",
      "[346]\ttrain-rmse:0.09479\teval-rmse:0.101314\ttrain-rmspe:0.133554\teval-rmspe:0.112666\n",
      "[347]\ttrain-rmse:0.094759\teval-rmse:0.10129\ttrain-rmspe:0.133506\teval-rmspe:0.112644\n",
      "[348]\ttrain-rmse:0.094708\teval-rmse:0.101265\ttrain-rmspe:0.133449\teval-rmspe:0.112604\n",
      "[349]\ttrain-rmse:0.094582\teval-rmse:0.101154\ttrain-rmspe:0.133325\teval-rmspe:0.112499\n",
      "[350]\ttrain-rmse:0.094487\teval-rmse:0.101088\ttrain-rmspe:0.13324\teval-rmspe:0.11243\n",
      "[351]\ttrain-rmse:0.09439\teval-rmse:0.100997\ttrain-rmspe:0.13316\teval-rmspe:0.112332\n",
      "[352]\ttrain-rmse:0.094312\teval-rmse:0.100934\ttrain-rmspe:0.133076\teval-rmspe:0.112274\n",
      "[353]\ttrain-rmse:0.09425\teval-rmse:0.100886\ttrain-rmspe:0.132929\teval-rmspe:0.112223\n",
      "[354]\ttrain-rmse:0.094145\teval-rmse:0.100794\ttrain-rmspe:0.132798\teval-rmspe:0.112142\n",
      "[355]\ttrain-rmse:0.09411\teval-rmse:0.100773\ttrain-rmspe:0.132867\teval-rmspe:0.112123\n",
      "[356]\ttrain-rmse:0.094053\teval-rmse:0.100743\ttrain-rmspe:0.132825\teval-rmspe:0.112117\n",
      "[357]\ttrain-rmse:0.094013\teval-rmse:0.100712\ttrain-rmspe:0.132796\teval-rmspe:0.112079\n",
      "[358]\ttrain-rmse:0.093945\teval-rmse:0.100662\ttrain-rmspe:0.132743\teval-rmspe:0.112038\n",
      "[359]\ttrain-rmse:0.09388\teval-rmse:0.100618\ttrain-rmspe:0.132695\teval-rmspe:0.111995\n",
      "[360]\ttrain-rmse:0.093818\teval-rmse:0.100581\ttrain-rmspe:0.132606\teval-rmspe:0.11196\n",
      "[361]\ttrain-rmse:0.093756\teval-rmse:0.100535\ttrain-rmspe:0.132543\teval-rmspe:0.111913\n",
      "[362]\ttrain-rmse:0.09369\teval-rmse:0.100491\ttrain-rmspe:0.132372\teval-rmspe:0.111872\n",
      "[363]\ttrain-rmse:0.093653\teval-rmse:0.100472\ttrain-rmspe:0.132343\teval-rmspe:0.111862\n",
      "[364]\ttrain-rmse:0.093612\teval-rmse:0.100444\ttrain-rmspe:0.132325\teval-rmspe:0.111831\n",
      "[365]\ttrain-rmse:0.093525\teval-rmse:0.100378\ttrain-rmspe:0.132239\teval-rmspe:0.11175\n",
      "[366]\ttrain-rmse:0.093482\teval-rmse:0.100357\ttrain-rmspe:0.132202\teval-rmspe:0.111735\n",
      "[367]\ttrain-rmse:0.093426\teval-rmse:0.100333\ttrain-rmspe:0.132145\teval-rmspe:0.111714\n",
      "[368]\ttrain-rmse:0.093377\teval-rmse:0.100306\ttrain-rmspe:0.132103\teval-rmspe:0.111695\n",
      "[369]\ttrain-rmse:0.093303\teval-rmse:0.100259\ttrain-rmspe:0.131992\teval-rmspe:0.111648\n",
      "[370]\ttrain-rmse:0.093227\teval-rmse:0.100202\ttrain-rmspe:0.131933\teval-rmspe:0.111591\n",
      "[371]\ttrain-rmse:0.093169\teval-rmse:0.100166\ttrain-rmspe:0.131899\teval-rmspe:0.111566\n",
      "[372]\ttrain-rmse:0.093102\teval-rmse:0.100114\ttrain-rmspe:0.131807\teval-rmspe:0.111518\n",
      "[373]\ttrain-rmse:0.093043\teval-rmse:0.100068\ttrain-rmspe:0.131746\teval-rmspe:0.111472\n",
      "[374]\ttrain-rmse:0.092996\teval-rmse:0.100035\ttrain-rmspe:0.131796\teval-rmspe:0.11144\n",
      "[375]\ttrain-rmse:0.092916\teval-rmse:0.099962\ttrain-rmspe:0.13172\teval-rmspe:0.111362\n",
      "[376]\ttrain-rmse:0.092841\teval-rmse:0.099894\ttrain-rmspe:0.131653\teval-rmspe:0.111285\n",
      "[377]\ttrain-rmse:0.092806\teval-rmse:0.099877\ttrain-rmspe:0.131628\teval-rmspe:0.111264\n",
      "[378]\ttrain-rmse:0.092769\teval-rmse:0.099859\ttrain-rmspe:0.131592\teval-rmspe:0.111242\n",
      "[379]\ttrain-rmse:0.092749\teval-rmse:0.099847\ttrain-rmspe:0.131574\teval-rmspe:0.111231\n",
      "[380]\ttrain-rmse:0.092723\teval-rmse:0.099829\ttrain-rmspe:0.131543\teval-rmspe:0.11121\n",
      "[381]\ttrain-rmse:0.092675\teval-rmse:0.099797\ttrain-rmspe:0.131479\teval-rmspe:0.111187\n",
      "[382]\ttrain-rmse:0.092648\teval-rmse:0.099779\ttrain-rmspe:0.131435\teval-rmspe:0.11117\n",
      "[383]\ttrain-rmse:0.092594\teval-rmse:0.099739\ttrain-rmspe:0.131387\teval-rmspe:0.111117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[384]\ttrain-rmse:0.092536\teval-rmse:0.099697\ttrain-rmspe:0.131311\teval-rmspe:0.111035\n",
      "[385]\ttrain-rmse:0.092485\teval-rmse:0.099673\ttrain-rmspe:0.131248\teval-rmspe:0.111019\n",
      "[386]\ttrain-rmse:0.09242\teval-rmse:0.099627\ttrain-rmspe:0.131181\teval-rmspe:0.110973\n",
      "[387]\ttrain-rmse:0.092384\teval-rmse:0.099602\ttrain-rmspe:0.131153\teval-rmspe:0.110943\n",
      "[388]\ttrain-rmse:0.092323\teval-rmse:0.09956\ttrain-rmspe:0.131097\teval-rmspe:0.110893\n",
      "[389]\ttrain-rmse:0.092244\teval-rmse:0.099495\ttrain-rmspe:0.131011\teval-rmspe:0.110827\n",
      "[390]\ttrain-rmse:0.092206\teval-rmse:0.099468\ttrain-rmspe:0.131032\teval-rmspe:0.110804\n",
      "[391]\ttrain-rmse:0.09215\teval-rmse:0.099431\ttrain-rmspe:0.130957\teval-rmspe:0.110764\n",
      "[392]\ttrain-rmse:0.092122\teval-rmse:0.099415\ttrain-rmspe:0.130932\teval-rmspe:0.11075\n",
      "[393]\ttrain-rmse:0.092084\teval-rmse:0.0994\ttrain-rmspe:0.128877\teval-rmspe:0.110738\n",
      "[394]\ttrain-rmse:0.092033\teval-rmse:0.099365\ttrain-rmspe:0.129093\teval-rmspe:0.110717\n",
      "[395]\ttrain-rmse:0.091968\teval-rmse:0.099305\ttrain-rmspe:0.129005\teval-rmspe:0.110603\n",
      "[396]\ttrain-rmse:0.09192\teval-rmse:0.099279\ttrain-rmspe:0.128938\teval-rmspe:0.110577\n",
      "[397]\ttrain-rmse:0.091894\teval-rmse:0.099265\ttrain-rmspe:0.128917\teval-rmspe:0.110564\n",
      "[398]\ttrain-rmse:0.09182\teval-rmse:0.099204\ttrain-rmspe:0.128862\teval-rmspe:0.110497\n",
      "[399]\ttrain-rmse:0.091784\teval-rmse:0.099189\ttrain-rmspe:0.128843\teval-rmspe:0.11048\n",
      "[400]\ttrain-rmse:0.091761\teval-rmse:0.099178\ttrain-rmspe:0.128817\teval-rmspe:0.110469\n",
      "[401]\ttrain-rmse:0.091686\teval-rmse:0.099127\ttrain-rmspe:0.128743\teval-rmspe:0.110419\n",
      "[402]\ttrain-rmse:0.091654\teval-rmse:0.09911\ttrain-rmspe:0.128707\teval-rmspe:0.110404\n",
      "[403]\ttrain-rmse:0.091599\teval-rmse:0.099081\ttrain-rmspe:0.127829\teval-rmspe:0.110379\n",
      "[404]\ttrain-rmse:0.091529\teval-rmse:0.099033\ttrain-rmspe:0.127776\teval-rmspe:0.110338\n",
      "[405]\ttrain-rmse:0.091484\teval-rmse:0.099006\ttrain-rmspe:0.127745\teval-rmspe:0.110319\n",
      "[406]\ttrain-rmse:0.091453\teval-rmse:0.098988\ttrain-rmspe:0.127717\teval-rmspe:0.110303\n",
      "[407]\ttrain-rmse:0.091424\teval-rmse:0.098972\ttrain-rmspe:0.127685\teval-rmspe:0.110283\n",
      "[408]\ttrain-rmse:0.091357\teval-rmse:0.098917\ttrain-rmspe:0.127626\teval-rmspe:0.1102\n",
      "[409]\ttrain-rmse:0.09132\teval-rmse:0.098898\ttrain-rmspe:0.127574\teval-rmspe:0.110181\n",
      "[410]\ttrain-rmse:0.091255\teval-rmse:0.098837\ttrain-rmspe:0.127524\teval-rmspe:0.110117\n",
      "[411]\ttrain-rmse:0.091217\teval-rmse:0.098809\ttrain-rmspe:0.127489\teval-rmspe:0.11009\n",
      "[412]\ttrain-rmse:0.091126\teval-rmse:0.09873\ttrain-rmspe:0.127411\teval-rmspe:0.110019\n",
      "[413]\ttrain-rmse:0.091098\teval-rmse:0.098712\ttrain-rmspe:0.127383\teval-rmspe:0.110007\n",
      "[414]\ttrain-rmse:0.091044\teval-rmse:0.098665\ttrain-rmspe:0.127273\teval-rmspe:0.109962\n",
      "[415]\ttrain-rmse:0.09101\teval-rmse:0.098654\ttrain-rmspe:0.127225\teval-rmspe:0.109956\n",
      "[416]\ttrain-rmse:0.090949\teval-rmse:0.098606\ttrain-rmspe:0.127168\teval-rmspe:0.109901\n",
      "[417]\ttrain-rmse:0.09093\teval-rmse:0.098599\ttrain-rmspe:0.127152\teval-rmspe:0.109893\n",
      "[418]\ttrain-rmse:0.090867\teval-rmse:0.098566\ttrain-rmspe:0.127015\teval-rmspe:0.10985\n",
      "[419]\ttrain-rmse:0.090834\teval-rmse:0.098543\ttrain-rmspe:0.126985\teval-rmspe:0.109828\n",
      "[420]\ttrain-rmse:0.090785\teval-rmse:0.098517\ttrain-rmspe:0.126951\teval-rmspe:0.109802\n",
      "[421]\ttrain-rmse:0.090742\teval-rmse:0.098486\ttrain-rmspe:0.126915\teval-rmspe:0.109768\n",
      "[422]\ttrain-rmse:0.090677\teval-rmse:0.098436\ttrain-rmspe:0.126854\teval-rmspe:0.109704\n",
      "[423]\ttrain-rmse:0.090636\teval-rmse:0.098409\ttrain-rmspe:0.127079\teval-rmspe:0.109677\n",
      "[424]\ttrain-rmse:0.090568\teval-rmse:0.098364\ttrain-rmspe:0.126678\teval-rmspe:0.109631\n",
      "[425]\ttrain-rmse:0.09053\teval-rmse:0.098351\ttrain-rmspe:0.126643\teval-rmspe:0.109611\n",
      "[426]\ttrain-rmse:0.090468\teval-rmse:0.098311\ttrain-rmspe:0.12658\teval-rmspe:0.109572\n",
      "[427]\ttrain-rmse:0.090406\teval-rmse:0.098261\ttrain-rmspe:0.126504\teval-rmspe:0.109522\n",
      "[428]\ttrain-rmse:0.090307\teval-rmse:0.098174\ttrain-rmspe:0.126426\teval-rmspe:0.109442\n",
      "[429]\ttrain-rmse:0.090222\teval-rmse:0.098108\ttrain-rmspe:0.126208\teval-rmspe:0.10935\n",
      "[430]\ttrain-rmse:0.090203\teval-rmse:0.098098\ttrain-rmspe:0.126196\teval-rmspe:0.109339\n",
      "[431]\ttrain-rmse:0.090161\teval-rmse:0.098077\ttrain-rmspe:0.126128\teval-rmspe:0.109314\n",
      "[432]\ttrain-rmse:0.090101\teval-rmse:0.098049\ttrain-rmspe:0.121085\teval-rmspe:0.109261\n",
      "[433]\ttrain-rmse:0.090064\teval-rmse:0.098029\ttrain-rmspe:0.121001\teval-rmspe:0.109241\n",
      "[434]\ttrain-rmse:0.090038\teval-rmse:0.098021\ttrain-rmspe:0.12094\teval-rmspe:0.109236\n",
      "[435]\ttrain-rmse:0.089995\teval-rmse:0.097994\ttrain-rmspe:0.120885\teval-rmspe:0.109193\n",
      "[436]\ttrain-rmse:0.08997\teval-rmse:0.097981\ttrain-rmspe:0.120867\teval-rmspe:0.10918\n",
      "[437]\ttrain-rmse:0.089926\teval-rmse:0.097949\ttrain-rmspe:0.120823\teval-rmspe:0.109145\n",
      "[438]\ttrain-rmse:0.089904\teval-rmse:0.097938\ttrain-rmspe:0.120807\teval-rmspe:0.109136\n",
      "[439]\ttrain-rmse:0.089857\teval-rmse:0.09791\ttrain-rmspe:0.120631\teval-rmspe:0.109113\n",
      "[440]\ttrain-rmse:0.089814\teval-rmse:0.097874\ttrain-rmspe:0.120598\teval-rmspe:0.109083\n",
      "[441]\ttrain-rmse:0.089781\teval-rmse:0.097856\ttrain-rmspe:0.120566\teval-rmspe:0.109068\n",
      "[442]\ttrain-rmse:0.089756\teval-rmse:0.097846\ttrain-rmspe:0.120543\teval-rmspe:0.109065\n",
      "[443]\ttrain-rmse:0.089724\teval-rmse:0.097833\ttrain-rmspe:0.120482\teval-rmspe:0.109054\n",
      "[444]\ttrain-rmse:0.089682\teval-rmse:0.097811\ttrain-rmspe:0.120443\teval-rmspe:0.109023\n",
      "[445]\ttrain-rmse:0.08963\teval-rmse:0.097772\ttrain-rmspe:0.120361\teval-rmspe:0.108985\n",
      "[446]\ttrain-rmse:0.089591\teval-rmse:0.097749\ttrain-rmspe:0.120332\teval-rmspe:0.108958\n",
      "[447]\ttrain-rmse:0.089542\teval-rmse:0.097718\ttrain-rmspe:0.12029\teval-rmspe:0.108927\n",
      "[448]\ttrain-rmse:0.089504\teval-rmse:0.097697\ttrain-rmspe:0.120247\teval-rmspe:0.1089\n",
      "[449]\ttrain-rmse:0.089452\teval-rmse:0.097671\ttrain-rmspe:0.120211\teval-rmspe:0.108877\n",
      "[450]\ttrain-rmse:0.089414\teval-rmse:0.097642\ttrain-rmspe:0.120067\teval-rmspe:0.108847\n",
      "[451]\ttrain-rmse:0.089402\teval-rmse:0.097635\ttrain-rmspe:0.120045\teval-rmspe:0.108831\n",
      "[452]\ttrain-rmse:0.089327\teval-rmse:0.097579\ttrain-rmspe:0.119932\teval-rmspe:0.108788\n",
      "[453]\ttrain-rmse:0.089298\teval-rmse:0.097563\ttrain-rmspe:0.119907\teval-rmspe:0.108774\n",
      "[454]\ttrain-rmse:0.089284\teval-rmse:0.097554\ttrain-rmspe:0.119898\teval-rmspe:0.108765\n",
      "[455]\ttrain-rmse:0.089236\teval-rmse:0.097515\ttrain-rmspe:0.11986\teval-rmspe:0.108736\n",
      "[456]\ttrain-rmse:0.089204\teval-rmse:0.097496\ttrain-rmspe:0.119832\teval-rmspe:0.108721\n",
      "[457]\ttrain-rmse:0.08915\teval-rmse:0.097452\ttrain-rmspe:0.119792\teval-rmspe:0.108676\n",
      "[458]\ttrain-rmse:0.089097\teval-rmse:0.097414\ttrain-rmspe:0.119746\teval-rmspe:0.108629\n",
      "[459]\ttrain-rmse:0.089063\teval-rmse:0.097385\ttrain-rmspe:0.119717\teval-rmspe:0.108601\n",
      "[460]\ttrain-rmse:0.089013\teval-rmse:0.097351\ttrain-rmspe:0.119657\teval-rmspe:0.108566\n",
      "[461]\ttrain-rmse:0.088979\teval-rmse:0.097328\ttrain-rmspe:0.119627\teval-rmspe:0.108544\n",
      "[462]\ttrain-rmse:0.088934\teval-rmse:0.097301\ttrain-rmspe:0.119558\teval-rmspe:0.108519\n",
      "[463]\ttrain-rmse:0.088893\teval-rmse:0.097275\ttrain-rmspe:0.119532\teval-rmspe:0.108491\n",
      "[464]\ttrain-rmse:0.088863\teval-rmse:0.097261\ttrain-rmspe:0.119517\teval-rmspe:0.108487\n",
      "[465]\ttrain-rmse:0.088811\teval-rmse:0.097233\ttrain-rmspe:0.119475\teval-rmspe:0.108452\n",
      "[466]\ttrain-rmse:0.088733\teval-rmse:0.097172\ttrain-rmspe:0.11937\teval-rmspe:0.10839\n",
      "[467]\ttrain-rmse:0.088711\teval-rmse:0.097159\ttrain-rmspe:0.119349\teval-rmspe:0.108377\n",
      "[468]\ttrain-rmse:0.088674\teval-rmse:0.097126\ttrain-rmspe:0.119318\teval-rmspe:0.10834\n",
      "[469]\ttrain-rmse:0.088614\teval-rmse:0.097085\ttrain-rmspe:0.11927\teval-rmspe:0.108303\n",
      "[470]\ttrain-rmse:0.088583\teval-rmse:0.09707\ttrain-rmspe:0.119234\teval-rmspe:0.108288\n",
      "[471]\ttrain-rmse:0.088523\teval-rmse:0.097023\ttrain-rmspe:0.11893\teval-rmspe:0.108241\n",
      "[472]\ttrain-rmse:0.088484\teval-rmse:0.097006\ttrain-rmspe:0.118895\teval-rmspe:0.108226\n",
      "[473]\ttrain-rmse:0.088464\teval-rmse:0.096993\ttrain-rmspe:0.118879\teval-rmspe:0.108215\n",
      "[474]\ttrain-rmse:0.088442\teval-rmse:0.096982\ttrain-rmspe:0.11886\teval-rmspe:0.108203\n",
      "[475]\ttrain-rmse:0.088403\teval-rmse:0.096951\ttrain-rmspe:0.118813\teval-rmspe:0.108167\n",
      "[476]\ttrain-rmse:0.08838\teval-rmse:0.096946\ttrain-rmspe:0.118793\teval-rmspe:0.108163\n",
      "[477]\ttrain-rmse:0.088354\teval-rmse:0.096935\ttrain-rmspe:0.118772\teval-rmspe:0.108155\n",
      "[478]\ttrain-rmse:0.088316\teval-rmse:0.096913\ttrain-rmspe:0.118737\teval-rmspe:0.108136\n",
      "[479]\ttrain-rmse:0.088259\teval-rmse:0.09687\ttrain-rmspe:0.118638\teval-rmspe:0.108111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[480]\ttrain-rmse:0.088222\teval-rmse:0.096855\ttrain-rmspe:0.118602\teval-rmspe:0.108103\n",
      "[481]\ttrain-rmse:0.088202\teval-rmse:0.096845\ttrain-rmspe:0.118588\teval-rmspe:0.108104\n",
      "[482]\ttrain-rmse:0.088165\teval-rmse:0.096832\ttrain-rmspe:0.118511\teval-rmspe:0.108093\n",
      "[483]\ttrain-rmse:0.088117\teval-rmse:0.096801\ttrain-rmspe:0.118492\teval-rmspe:0.108066\n",
      "[484]\ttrain-rmse:0.088085\teval-rmse:0.096786\ttrain-rmspe:0.118458\teval-rmspe:0.108054\n",
      "[485]\ttrain-rmse:0.088038\teval-rmse:0.096755\ttrain-rmspe:0.118417\teval-rmspe:0.108026\n",
      "[486]\ttrain-rmse:0.088\teval-rmse:0.096723\ttrain-rmspe:0.118392\teval-rmspe:0.108001\n",
      "[487]\ttrain-rmse:0.087982\teval-rmse:0.096716\ttrain-rmspe:0.118377\teval-rmspe:0.108001\n",
      "[488]\ttrain-rmse:0.087948\teval-rmse:0.096695\ttrain-rmspe:0.118344\teval-rmspe:0.107983\n",
      "[489]\ttrain-rmse:0.087928\teval-rmse:0.096688\ttrain-rmspe:0.11832\teval-rmspe:0.107977\n",
      "[490]\ttrain-rmse:0.087875\teval-rmse:0.096676\ttrain-rmspe:0.114696\teval-rmspe:0.107962\n",
      "[491]\ttrain-rmse:0.087858\teval-rmse:0.09667\ttrain-rmspe:0.114672\teval-rmspe:0.107958\n",
      "[492]\ttrain-rmse:0.087836\teval-rmse:0.09666\ttrain-rmspe:0.114652\teval-rmspe:0.10795\n",
      "[493]\ttrain-rmse:0.087811\teval-rmse:0.096647\ttrain-rmspe:0.114633\teval-rmspe:0.107935\n",
      "[494]\ttrain-rmse:0.08777\teval-rmse:0.09662\ttrain-rmspe:0.114582\teval-rmspe:0.107856\n",
      "[495]\ttrain-rmse:0.087723\teval-rmse:0.096592\ttrain-rmspe:0.114536\teval-rmspe:0.107831\n",
      "[496]\ttrain-rmse:0.08768\teval-rmse:0.096571\ttrain-rmspe:0.114482\teval-rmspe:0.107804\n",
      "[497]\ttrain-rmse:0.087633\teval-rmse:0.096545\ttrain-rmspe:0.114456\teval-rmspe:0.107805\n",
      "[498]\ttrain-rmse:0.087606\teval-rmse:0.096524\ttrain-rmspe:0.114426\teval-rmspe:0.107781\n",
      "[499]\ttrain-rmse:0.087574\teval-rmse:0.096504\ttrain-rmspe:0.114405\teval-rmspe:0.107758\n"
     ]
    }
   ],
   "source": [
    "watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "gbm = xgb.train(params, dtrain, num_boost_round, evals=watchlist, \\\n",
    "  early_stopping_rounds=100, feval=rmspe_xg, verbose_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make predictions on the test set\n"
     ]
    }
   ],
   "source": [
    "print(\"Make predictions on the test set\")\n",
    "dtest = xgb.DMatrix(test[features])\n",
    "test_probs = gbm.predict(dtest)\n",
    "# Make Submission\n",
    "result = pd.DataFrame({\"Id\": test[\"Id\"], 'Sales': np.expm1(test_probs)})\n",
    "result.to_csv(\"xgboost_submission_final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_num = {'Jan' : 1,'Feb' : 2,'Mar' : 3,'Apr' : 4,'May' : 5,'Jun' : 6,'Jul' : 7,'Aug' : 8,'Sept' : 9, 'Oct' : 10,\n",
    "            'Nov' : 11,'Dec' : 12 }\n",
    "\n",
    "def monthToNum(date):\n",
    "    return{\n",
    "            'Jan' : 1,\n",
    "            'Feb' : 2,\n",
    "            'Mar' : 3,\n",
    "            'Apr' : 4,\n",
    "            'May' : 5,\n",
    "            'Jun' : 6,\n",
    "            'Jul' : 7,\n",
    "            'Aug' : 8,\n",
    "            'Sept' : 9, \n",
    "            'Oct' : 10,\n",
    "            'Nov' : 11,\n",
    "            'Dec' : 12\n",
    "    }[date]\n",
    "\n",
    "df_store['PromoInterval0'] = df_store['PromoInterval0'].map(lambda x: monthToNum(x) if str(x) != 'nan' else np.nan)\n",
    "df_store['PromoInterval1'] = df_store['PromoInterval1'].map(lambda x: monthToNum(x) if str(x) != 'nan' else np.nan)\n",
    "df_store['PromoInterval2'] = df_store['PromoInterval2'].map(lambda x: monthToNum(x) if str(x) != 'nan' else np.nan)\n",
    "df_store['PromoInterval3'] = df_store['PromoInterval3'].map(lambda x: monthToNum(x) if str(x) != 'nan' else np.nan)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
